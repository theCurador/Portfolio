{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f748ba2-de0d-468f-bf76-2940217c57b5",
   "metadata": {},
   "source": [
    "# The First Machine Learning Model\n",
    "\n",
    "Building my first model. Hurray!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bdf84-e8e5-42d8-8b33-c0c5cad5a55c",
   "metadata": {},
   "source": [
    "## Selecting Data for Modeling\n",
    "\n",
    "The dataset had too many variables to wrap our head around, or even to print out nicely. How can I pare down this overwhelming amount of data to something we can understand?\n",
    "\n",
    "We'll start by picking a few variables using our intuition. Later courses will show you statistical techniques to automatically prioritize variables. \n",
    "\n",
    "To choose variables/columns, we'll need to see a list of all columns in the dataset. That is done with the **columns** property of the **DataFrame** (*the bottom line of code below*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7af383-f328-4bd1-a99e-6543c9eccb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "melbourne_path = '/Users/jeanzayas/Desktop/Divergence/DATA ANALYSIS/Learning/ML kaggle learn/Data_ML_try/Melbourne Housing/melb_data.csv'\n",
    "\n",
    "melbourne_data = pd.read_csv(melbourne_path)\n",
    "melbourne_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e2ef6-9e87-42eb-9085-7f953aba4b07",
   "metadata": {},
   "source": [
    " The Melbourne data has some missing values (some houses for which some variables weren't recorded.)\n",
    "\n",
    "We'll learn to handle the missing values later. \n",
    "\n",
    "Your Iowa data doesn't have missing values in teh columns you use.\n",
    "\n",
    "So we will take the simplest option for now, and drop houses from our data. \n",
    "\n",
    "Don't worry about this much for now, though the code is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24498c0-e0bb-48e0-b409-cfdd160414c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80790</td>\n",
       "      <td>144.99340</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.00</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80930</td>\n",
       "      <td>144.99440</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>55a Park St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>VB</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>4/06/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>142.00</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80720</td>\n",
       "      <td>144.99410</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>124 Yarra St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1876000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>7/05/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>210.00</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80240</td>\n",
       "      <td>144.99930</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>98 Charles St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1636000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>8/10/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>107.00</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80600</td>\n",
       "      <td>144.99540</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12205</th>\n",
       "      <td>Whittlesea</td>\n",
       "      <td>30 Sherwin St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>601000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Ray</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>35.5</td>\n",
       "      <td>3757.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>149.00</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Whittlesea</td>\n",
       "      <td>-37.51232</td>\n",
       "      <td>145.13282</td>\n",
       "      <td>Northern Victoria</td>\n",
       "      <td>2170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12206</th>\n",
       "      <td>Williamstown</td>\n",
       "      <td>75 Cecil St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1050000.0</td>\n",
       "      <td>VB</td>\n",
       "      <td>Williams</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>Hobsons Bay</td>\n",
       "      <td>-37.86558</td>\n",
       "      <td>144.90474</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12207</th>\n",
       "      <td>Williamstown</td>\n",
       "      <td>2/29 Dover Rd</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>385000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Williams</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.64</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>Hobsons Bay</td>\n",
       "      <td>-37.85588</td>\n",
       "      <td>144.89936</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12209</th>\n",
       "      <td>Windsor</td>\n",
       "      <td>201/152 Peel St</td>\n",
       "      <td>2</td>\n",
       "      <td>u</td>\n",
       "      <td>560000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>hockingstuart</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.60</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Stonnington</td>\n",
       "      <td>-37.85581</td>\n",
       "      <td>144.99025</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>4380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12212</th>\n",
       "      <td>Yarraville</td>\n",
       "      <td>54 Pentland Pde</td>\n",
       "      <td>6</td>\n",
       "      <td>h</td>\n",
       "      <td>2450000.0</td>\n",
       "      <td>VB</td>\n",
       "      <td>Village</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3013.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>388.50</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>Maribyrnong</td>\n",
       "      <td>-37.81038</td>\n",
       "      <td>144.89389</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6543.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6196 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Suburb          Address  Rooms Type      Price Method  \\\n",
       "1        Abbotsford  25 Bloomburg St      2    h  1035000.0      S   \n",
       "2        Abbotsford     5 Charles St      3    h  1465000.0     SP   \n",
       "4        Abbotsford      55a Park St      4    h  1600000.0     VB   \n",
       "6        Abbotsford     124 Yarra St      3    h  1876000.0      S   \n",
       "7        Abbotsford    98 Charles St      2    h  1636000.0      S   \n",
       "...             ...              ...    ...  ...        ...    ...   \n",
       "12205    Whittlesea    30 Sherwin St      3    h   601000.0      S   \n",
       "12206  Williamstown      75 Cecil St      3    h  1050000.0     VB   \n",
       "12207  Williamstown    2/29 Dover Rd      1    u   385000.0     SP   \n",
       "12209       Windsor  201/152 Peel St      2    u   560000.0     PI   \n",
       "12212    Yarraville  54 Pentland Pde      6    h  2450000.0     VB   \n",
       "\n",
       "             SellerG        Date  Distance  Postcode  ...  Bathroom  Car  \\\n",
       "1             Biggin   4/02/2016       2.5    3067.0  ...       1.0  0.0   \n",
       "2             Biggin   4/03/2017       2.5    3067.0  ...       2.0  0.0   \n",
       "4             Nelson   4/06/2016       2.5    3067.0  ...       1.0  2.0   \n",
       "6             Nelson   7/05/2016       2.5    3067.0  ...       2.0  0.0   \n",
       "7             Nelson   8/10/2016       2.5    3067.0  ...       1.0  2.0   \n",
       "...              ...         ...       ...       ...  ...       ...  ...   \n",
       "12205            Ray  29/07/2017      35.5    3757.0  ...       2.0  1.0   \n",
       "12206       Williams  29/07/2017       6.8    3016.0  ...       1.0  0.0   \n",
       "12207       Williams  29/07/2017       6.8    3016.0  ...       1.0  1.0   \n",
       "12209  hockingstuart  29/07/2017       4.6    3181.0  ...       1.0  1.0   \n",
       "12212        Village  29/07/2017       6.3    3013.0  ...       3.0  2.0   \n",
       "\n",
       "       Landsize  BuildingArea  YearBuilt  CouncilArea Lattitude  Longtitude  \\\n",
       "1         156.0         79.00     1900.0        Yarra -37.80790   144.99340   \n",
       "2         134.0        150.00     1900.0        Yarra -37.80930   144.99440   \n",
       "4         120.0        142.00     2014.0        Yarra -37.80720   144.99410   \n",
       "6         245.0        210.00     1910.0        Yarra -37.80240   144.99930   \n",
       "7         256.0        107.00     1890.0        Yarra -37.80600   144.99540   \n",
       "...         ...           ...        ...          ...       ...         ...   \n",
       "12205     972.0        149.00     1996.0   Whittlesea -37.51232   145.13282   \n",
       "12206     179.0        115.00     1890.0  Hobsons Bay -37.86558   144.90474   \n",
       "12207       0.0         35.64     1967.0  Hobsons Bay -37.85588   144.89936   \n",
       "12209       0.0         61.60     2012.0  Stonnington -37.85581   144.99025   \n",
       "12212    1087.0        388.50     1920.0  Maribyrnong -37.81038   144.89389   \n",
       "\n",
       "                  Regionname Propertycount  \n",
       "1      Northern Metropolitan        4019.0  \n",
       "2      Northern Metropolitan        4019.0  \n",
       "4      Northern Metropolitan        4019.0  \n",
       "6      Northern Metropolitan        4019.0  \n",
       "7      Northern Metropolitan        4019.0  \n",
       "...                      ...           ...  \n",
       "12205      Northern Victoria        2170.0  \n",
       "12206   Western Metropolitan        6380.0  \n",
       "12207   Western Metropolitan        6380.0  \n",
       "12209  Southern Metropolitan        4380.0  \n",
       "12212   Western Metropolitan        6543.0  \n",
       "\n",
       "[6196 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "melbourne_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895e95ea-8ea9-46de-801c-ba5b5b8a4893",
   "metadata": {},
   "source": [
    "There are many ways to select a subset of your data. The **Pandas course** covers these in more depth, but we will focus on two approaches for now. \n",
    "\n",
    "    1. Dot notation, which we use to select the \"prediction target\"\n",
    "    2. Selecting with a column list, which we use to selct the \"features\"\n",
    "   \n",
    "### Selecting The Prediction Target\n",
    "\n",
    "You can pull out a variable with **dot-notation**. This single column is stored in a **Series**, which is broadly like a DataFrame with only a single column of data. \n",
    "\n",
    "We'll use the dot notation to select the column we want to predict, which is called the **prediction target**. By convetion, the prediction target is called **y**. So the code we need to save the house prices in the Melbourne data is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d4720e-a294-4df0-8110-293b34aba009",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = melbourne_data.Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb58fa2-a335-4645-9fa1-d1e5f4a16d49",
   "metadata": {},
   "source": [
    "### Choosing \"Features\"\n",
    "\n",
    "The columns that are inputted into our model (and later used to make predictions) are called \"features\". In our case, those would be the columns used to determine the home price. Sometimes, you will use all columns except the target as features. Other times you'll be better off with fewer features. \n",
    "\n",
    "For now, we'll build a model with only a few features. Later on you'll see how to iterate and compare models built with different features. \n",
    "\n",
    "we select multiple features by providing a list of column names inside brackets. Each item in that list should be a string (with quotes).\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dddc579-82f8-4180-aefc-56dc521ac385",
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff461c-b635-4bfe-9b73-f75bb0ad9e3b",
   "metadata": {},
   "source": [
    "By convention, this data is called **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3832e0f2-d582-46ba-9164-7e2322f57d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = melbourne_data[melbourne_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a90d5-c011-4594-ba5a-0ae6d416569d",
   "metadata": {},
   "source": [
    "Let's quickly review the data we'll be using to predict house prices using the describe method and the head method, which shows the top few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4b80a39-90b3-45f2-b6a4-d02e8b67d9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.931407</td>\n",
       "      <td>1.576340</td>\n",
       "      <td>471.006940</td>\n",
       "      <td>141.568645</td>\n",
       "      <td>1964.081988</td>\n",
       "      <td>-37.807904</td>\n",
       "      <td>144.990201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.971079</td>\n",
       "      <td>0.711362</td>\n",
       "      <td>897.449881</td>\n",
       "      <td>90.834824</td>\n",
       "      <td>38.105673</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.099165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>-38.164920</td>\n",
       "      <td>144.542370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.855438</td>\n",
       "      <td>144.926198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.802250</td>\n",
       "      <td>144.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>-37.758200</td>\n",
       "      <td>145.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37000.000000</td>\n",
       "      <td>3112.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>-37.457090</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rooms     Bathroom      Landsize  BuildingArea    YearBuilt  \\\n",
       "count  6196.000000  6196.000000   6196.000000   6196.000000  6196.000000   \n",
       "mean      2.931407     1.576340    471.006940    141.568645  1964.081988   \n",
       "std       0.971079     0.711362    897.449881     90.834824    38.105673   \n",
       "min       1.000000     1.000000      0.000000      0.000000  1196.000000   \n",
       "25%       2.000000     1.000000    152.000000     91.000000  1940.000000   \n",
       "50%       3.000000     1.000000    373.000000    124.000000  1970.000000   \n",
       "75%       4.000000     2.000000    628.000000    170.000000  2000.000000   \n",
       "max       8.000000     8.000000  37000.000000   3112.000000  2018.000000   \n",
       "\n",
       "         Lattitude   Longtitude  \n",
       "count  6196.000000  6196.000000  \n",
       "mean    -37.807904   144.990201  \n",
       "std       0.075850     0.099165  \n",
       "min     -38.164920   144.542370  \n",
       "25%     -37.855438   144.926198  \n",
       "50%     -37.802250   144.995800  \n",
       "75%     -37.758200   145.052700  \n",
       "max     -37.457090   145.526350  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602f3466-f5aa-4280-be33-1b8c761a3daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>-37.8024</td>\n",
       "      <td>144.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>-37.8060</td>\n",
       "      <td>144.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms  Bathroom  Landsize  BuildingArea  YearBuilt  Lattitude  Longtitude\n",
       "1      2       1.0     156.0          79.0     1900.0   -37.8079    144.9934\n",
       "2      3       2.0     134.0         150.0     1900.0   -37.8093    144.9944\n",
       "4      4       1.0     120.0         142.0     2014.0   -37.8072    144.9941\n",
       "6      3       2.0     245.0         210.0     1910.0   -37.8024    144.9993\n",
       "7      2       1.0     256.0         107.0     1890.0   -37.8060    144.9954"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ca4a1-bf61-4f34-9550-e20fd87c2b28",
   "metadata": {},
   "source": [
    "Visually checking your data with these commands is an important part of a data scientist's job. You'll frequently find surprises in the dataset that deserve your inspector skills.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b7e99-ab23-4255-ae77-8519e244690a",
   "metadata": {},
   "source": [
    "--------------------------------------------------\n",
    "\n",
    "## Building Your Model\n",
    "\n",
    "I will use the **scikit-learn** library to create my models. When coding, this library is written as **sklearn**, as you will see in the sample code. **Scikit-learn** is easily the most popular library for modeling the types of data typically stored in **DataFrames**.\n",
    "\n",
    "The steps to building the model are:\n",
    " \n",
    "   1. **Define**: What type of model will it be? A decision tree? Some other type of model?\n",
    "   *Some other parameters of the model type are specified too.*\n",
    "   \n",
    "   2. **Fit**: Capture patterns from provided data. This is the heart of modeling. \n",
    "   3. **Predict**: Just what it sounds like\n",
    "   4. **Evaluate**: Determine how accurate the model's predictions are. \n",
    "   \n",
    "Here is an example of defining a decision tree model with scikit-learn and fitting it with the features and target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e91ac57-2cd5-49b4-9729-73c7cfb4e872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit model\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739195c-92d7-4966-b33d-e6bfc4895133",
   "metadata": {},
   "source": [
    "Many machine learning models allow some randomness in model training. Specifying a number for <mark>random_state</mark> ensures that I get the same results in each run. This is considered a good practice. You use any number, and model quality won't depend meaningfully on exactly what value you choose. \n",
    "\n",
    "We now have a fitted model that we can use to make predicitons. \n",
    "\n",
    "In practice, I'll want to make predictions for new houses coming on the market rather than the houses we already have prices for. But I'll make predictions for the first few rows of the training data to see how the predict function works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa867802-b830-4b13-adee-eb0111292d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the following 5 houses:\n",
      "   Rooms  Bathroom  Landsize  BuildingArea  YearBuilt  Lattitude  Longtitude\n",
      "1      2       1.0     156.0          79.0     1900.0   -37.8079    144.9934\n",
      "2      3       2.0     134.0         150.0     1900.0   -37.8093    144.9944\n",
      "4      4       1.0     120.0         142.0     2014.0   -37.8072    144.9941\n",
      "6      3       2.0     245.0         210.0     1910.0   -37.8024    144.9993\n",
      "7      2       1.0     256.0         107.0     1890.0   -37.8060    144.9954\n",
      "The predictions are\n",
      "[1035000. 1465000. 1600000. 1876000. 1636000.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec6d2f1-b798-4362-b7cf-c0b430579ecd",
   "metadata": {},
   "source": [
    "## RECAP\n",
    "\n",
    "So far, I have loaded the data and reviewed it with the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec7cce7b-ac98-48a7-940a-3c894120176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Path of the file to read \n",
    "iowa_file = '/Users/jeanzayas/Desktop/Divergence/DATA ANALYSIS/Learning/ML kaggle learn/Data_ML_try/Housing Prices/train.csv'\n",
    "\n",
    "iowa_data = pd.read_csv(iowa_file)\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a51fc2-37ee-4744-a3e6-ae9e60b6b829",
   "metadata": {},
   "source": [
    "## Step 1: Specify Predicion Target\n",
    "\n",
    "Selecct the target variable, which corresponds to the sales price. Save this to a new variable called <mark>y</mark>. You'll need to print a list of the columns to find the name of the column you need. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b66e24f8-4a6a-4859-b7ec-5546b8a928b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# print a list of columns in the dataset to find the name of the prediction target\n",
    "\n",
    "iowa_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548fe464-be61-421d-8d96-f0f69798bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iowa_data.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e76b6e-7b75-4201-bb47-9a7642cf17cf",
   "metadata": {},
   "source": [
    "## Step 2: Create X \n",
    "\n",
    "Now I will create a **DataFrame** called <mark>**X**</mark>.\n",
    "\n",
    "Since we only want some columns from the original data,  first we will create a list with the names of the columns we want in <mark>**X**</mark>.\n",
    "\n",
    "Using just the following columns in the list:\n",
    "\n",
    "  - LotArea\n",
    "  - YearBuilt\n",
    "  - 1stFlrSF\n",
    "  - 2ndFlrSF\n",
    "  - FullBath\n",
    "  - BedroomAbvGr\n",
    "  - TotRmsAbvGrd\n",
    " \n",
    "After we've created that list of features, use it to create the **DataFrame** that we'll use to fi the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9426145-a7e6-44f0-bcdc-6eeda81a5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create this list of features below\n",
    "\n",
    "feature_names = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "\n",
    "# Select data corresponding to features in feature_names\n",
    "\n",
    "X = iowa_data[feature_names]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912e7b3-457b-497c-ae88-2c1a37812756",
   "metadata": {},
   "source": [
    "## Review Data\n",
    "\n",
    "Before building a model, take a quick look at <mark>**X**</mark> to verify it looks sensible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d69cbc3a-45c8-411a-aac2-2f2af1515bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10516.828082</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1162.626712</td>\n",
       "      <td>346.992466</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>6.517808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9981.264932</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>386.587738</td>\n",
       "      <td>436.528436</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>1.625393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7553.500000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9478.500000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11601.500000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1391.250000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215245.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>4692.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LotArea    YearBuilt     1stFlrSF     2ndFlrSF     FullBath  \\\n",
       "count    1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean    10516.828082  1971.267808  1162.626712   346.992466     1.565068   \n",
       "std      9981.264932    30.202904   386.587738   436.528436     0.550916   \n",
       "min      1300.000000  1872.000000   334.000000     0.000000     0.000000   \n",
       "25%      7553.500000  1954.000000   882.000000     0.000000     1.000000   \n",
       "50%      9478.500000  1973.000000  1087.000000     0.000000     2.000000   \n",
       "75%     11601.500000  2000.000000  1391.250000   728.000000     2.000000   \n",
       "max    215245.000000  2010.000000  4692.000000  2065.000000     3.000000   \n",
       "\n",
       "       BedroomAbvGr  TotRmsAbvGrd  \n",
       "count   1460.000000   1460.000000  \n",
       "mean       2.866438      6.517808  \n",
       "std        0.815778      1.625393  \n",
       "min        0.000000      2.000000  \n",
       "25%        2.000000      5.000000  \n",
       "50%        3.000000      6.000000  \n",
       "75%        3.000000      7.000000  \n",
       "max        8.000000     14.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review data\n",
    "\n",
    "# print description or statistics from X\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67ea892-269e-4ce0-a8cc-7600beb3018c",
   "metadata": {},
   "source": [
    "## Step 3: Specify and Fit Model\n",
    "\n",
    "Create a <mark>DecisionTreeRegressor</mark> and save it iowa_model. Ensure you've donme the relevant import from sklearn to run this command.\n",
    "\n",
    "Then fit the model you just created using teh data in <mark>X</mark> and <mark>Y</mark> that you saved above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d97f93c4-9952-4928-a14b-6c1f3bce01eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "iowa_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af296d-5f78-418d-8b85-44f7cec4128e",
   "metadata": {},
   "source": [
    "## Step 4: Make Predicitions \n",
    "\n",
    "Make predictions with the model's <mark>*predict*</mark> command using <mark>X</mark> as the data. Save the results to a variable called <mark>predictions</mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6ccc975-1521-4555-b075-d5b9c64ea765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208500. 181500. 223500. ... 266500. 142125. 147500.]\n"
     ]
    }
   ],
   "source": [
    "predictions = iowa_model.predict(X)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a50d3a-e04e-4a6a-ba2f-5bc2131698b8",
   "metadata": {},
   "source": [
    "# __________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a80ae9-54a9-4ef5-b730-572ea6058d04",
   "metadata": {},
   "source": [
    "# Model Validation \n",
    "\n",
    "Measure the performance of your model, so you can test and compare alternatives. \n",
    "\n",
    "You've built a model. But how good is it? \n",
    "\n",
    "In this lesson, you will learn to use model validatiopn to measure the quality of your model. Measuring model quality is the key to iteratively improving your models. \n",
    "\n",
    "### What is Model Validation \n",
    "\n",
    "You'll want to evaluate almost every model you ever build. In most (though not all) applications, The relecant measure of model quality is predictive accuracy. In other words, will the model's predictions be close to what actually happens. \n",
    "\n",
    "Many people make a huge mistake when measuring predictive accuracy. They make predictions with their training data. You'll see the problem with this approach and how to solve it in a moment, but let's think about how we'd do this first.\n",
    "\n",
    "We first need to summarize the model quality into a understandable way. If you compare predicted and actual home values for 10,000 houses, you'll likely find a mix of good and bad predictions. Looking through a list of 10,000 predicted and actual values would be pointless. We need to summarize this into a single metric.\n",
    "\n",
    "There are many metrics for summarizing model quality, but we'll start with one called **Mean Absoluty Error** (also called **MAE**). Let's break down this metric starting with the last word, error. \n",
    "\n",
    "The prediction error for each house is:\n",
    ">\n",
    "$error=actual-predicted\n",
    "\n",
    "\n",
    "So, if a house cost 150,000 dollars and you predicted it would cost 100,000 dollars the error is $50,000.\n",
    "\n",
    "With the **MAE** metric, we take the absolute value of each error. This converts each error to a positive number. We then Take the average of those absolute errors. This is our measure of model quality. In plain English, it can be said as \n",
    "\n",
    "    - *On average, our predictions are off by about X.\n",
    " \n",
    "To calculate **MAE**, we first need a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a59555a5-5d9c-4b4a-bb6f-7b879fab3488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30187d-c316-4288-88f4-a25707633f50",
   "metadata": {},
   "source": [
    "Once we have a model, here is how we calculate the mean absolute error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7cbb44c-9650-4e0b-9d5c-00a42e2b4d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.35433789954339"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587930f2-39b9-4b28-9069-f4225b8263df",
   "metadata": {},
   "source": [
    "### The Problem with \"In-Sample\" Scores\n",
    "\n",
    "The measure we just computed can be called an \"in-sample\" score. We used a single \"sample\" of houses for both building the model and evaluating it. Here's why this is bad.\n",
    "\n",
    "Imagine that, in the large real estate market, door color is unrelated to home price.\n",
    "\n",
    "However, in the sample of data you used to build the model, all homes with green doors were very expensive. The model's job is to find patterns that predict home prices, so it will see this pattern, and it will always predict high prices for homes with green doors.\n",
    "\n",
    "Since this pattern was derived from the training data, the model will appear accurate in the training data.\n",
    "\n",
    "But if this pattern doesn't hold when the model sees new data, the model would be very inaccurate when used in practice.\n",
    "\n",
    "Since models' practical value come from making predictions on new data, we measure performance on data that wasn't used to build the model. The most straightforward way to do this is to exclude some data from the model-building process, and then use those to test the model's accuracy on data it hasn't seen before. This data is called **validation data**.\n",
    "\n",
    "### Coding It\n",
    "\n",
    "The scikit-learn library has a function train_test_split to break up the data into two pieces. We'll use some of that data as training data to fit the model, and we'll use the other data as validation data to calculate mean_absolute_error.\n",
    "\n",
    "Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e41e9ff3-d627-4206-b259-ffd80db23ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29652.931506849316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supllying a numeric value to \n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script. \n",
    "\n",
    "\n",
    "# when creating the model change the state to 1\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "# Define model\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "# get predicted prices on validation data\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a2ee7a-c734-4ba6-a6b6-75a821467962",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "**Wow!**\n",
    "\n",
    "Our mean absolute error for the in-sample data was about 65 dollars. Out-of-sample it's less than 40,000 dollars.\n",
    "\n",
    "This is the difference between a model that is almost exactly right, and one that is unusable for most practical purposes. As a point of reference, the average home value in the validation data is 1.1 million dollars. So the rror in new data is about a quarter of the averge home value. \n",
    "\n",
    "There are many ways to improve this model, such as experimenting to find better features or different model types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d055a8-1073-484a-ad02-9f158bc81fd6",
   "metadata": {},
   "source": [
    "## RECAP\n",
    "\n",
    "Let's test how good the model is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b5c5ac0-52f4-4f08-b452-3451401a818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First in-sample predicitons: [208500. 181500. 223500. 140000. 250000.]\n",
      "Actual target values for those homes: [208500, 181500, 223500, 140000, 250000]\n"
     ]
    }
   ],
   "source": [
    "print(\"First in-sample predicitons:\", iowa_model.predict(X.head()))\n",
    "print(\"Actual target values for those homes:\", y.head().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249ebd8-7597-4db6-968f-81f2b328d38a",
   "metadata": {},
   "source": [
    "### Step 1: Split your data\n",
    "\n",
    "Use the train_test_split function to split up your data. \n",
    "\n",
    "Give it the argument random_state=1 so teh check functions know what to expect when verifying your code. \n",
    "\n",
    "Recall, your features are loaded in the DataFrame **X** and your target is loaded in **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bffed51-af7f-40a1-abcb-ddc82b780bdd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "6       10084       2004      1694         0         2             3   \n",
      "807     21384       1923      1072       504         1             3   \n",
      "955      7136       1946       979       979         2             4   \n",
      "1040    13125       1957      1803         0         2             3   \n",
      "701      9600       1969      1164         0         1             3   \n",
      "...       ...        ...       ...       ...       ...           ...   \n",
      "715     10140       1974      1350         0         2             3   \n",
      "905      9920       1954      1063         0         1             3   \n",
      "1096     6882       1914       773       582         1             3   \n",
      "235      1680       1971       483       504         1             2   \n",
      "1061    18000       1935       894         0         1             2   \n",
      "\n",
      "      TotRmsAbvGrd  \n",
      "6                7  \n",
      "807              6  \n",
      "955              8  \n",
      "1040             8  \n",
      "701              6  \n",
      "...            ...  \n",
      "715              7  \n",
      "905              6  \n",
      "1096             7  \n",
      "235              5  \n",
      "1061             6  \n",
      "\n",
      "[1095 rows x 7 columns]       LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "258     12435       2001       963       829         2             3   \n",
      "267      8400       1939      1052       720         2             4   \n",
      "288      9819       1967       900         0         1             3   \n",
      "649      1936       1970       630         0         1             1   \n",
      "1233    12160       1959      1188         0         1             3   \n",
      "...       ...        ...       ...       ...       ...           ...   \n",
      "1017     5814       1984      1360         0         1             1   \n",
      "534      9056       2004       707       707         2             3   \n",
      "1334     2368       1970       765       600         1             3   \n",
      "1369    10635       2003      1668         0         2             3   \n",
      "628     11606       1969      1040      1040         1             5   \n",
      "\n",
      "      TotRmsAbvGrd  \n",
      "258              7  \n",
      "267              8  \n",
      "288              5  \n",
      "649              3  \n",
      "1233             6  \n",
      "...            ...  \n",
      "1017             4  \n",
      "534              6  \n",
      "1334             7  \n",
      "1369             8  \n",
      "628              9  \n",
      "\n",
      "[365 rows x 7 columns] 6       307000\n",
      "807     223500\n",
      "955     145000\n",
      "1040    155000\n",
      "701     140000\n",
      "         ...  \n",
      "715     165000\n",
      "905     128000\n",
      "1096    127000\n",
      "235      89500\n",
      "1061     81000\n",
      "Name: SalePrice, Length: 1095, dtype: int64 258     231500\n",
      "267     179500\n",
      "288     122000\n",
      "649      84500\n",
      "1233    142000\n",
      "Name: SalePrice, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import the train_test_split function \n",
    "print(train_X, val_X, train_y, val_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c796d597-a7c9-4f73-a9eb-f5ad5b58ca32",
   "metadata": {},
   "source": [
    "### Step 2: Specify and Fit the Model\n",
    "\n",
    "Create a DecisionTreeRegressor model and fit it to the relevant data. Set random_state to 1 again when creating the model. \n",
    "\n",
    "We imported **DecisionTreeRegressor** in your last exercise and that code has been copied tot he setup code aboce. So, no need to import it again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bfe3467-b6a4-4ac4-a76b-c00c65377a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(random_state=1)\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit iowa_model with the training data.\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Check your answer\n",
    "print(iowa_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3794a-f729-49e1-a55d-01a74f4fbf67",
   "metadata": {},
   "source": [
    "### Step 3: Make Predictions with Validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeb59cc1-9a66-495a-9120-eec630e6c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with all validation observations \n",
    "\n",
    "val_predictions = iowa_model.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a86aa89f-468d-4db3-b2b9-0cd478630eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The top few validations predictions are: 186500.0 ,  184000.0 ,  130000.0 ,  92000.0 ,  164500.0\n",
      "The top few actual prices from validation data:  [34900 35311 37900 39300 40000 52000]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# print the top few validations predictions \n",
    "print(\" The top few validations predictions are:\", \n",
    "      val_predictions[0],', '\n",
    "     ,val_predictions[1],', '\n",
    "     ,val_predictions[2],', '\n",
    "     ,val_predictions[3],', '\n",
    "     ,val_predictions[4]\n",
    "     )\n",
    "# print the top few actual prices from validation data \n",
    "\n",
    "print(\"The top few actual prices from validation data: \", np.sort(y, kind=\"quicksort\")[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c770ccc5-5fb5-4110-9dd7-3523fdce8dff",
   "metadata": {},
   "source": [
    "What do you notice that is different from what you saw with in-sample predictions (which are printed after the top code cell in this page).\n",
    "\n",
    "Do you remember why validation predictions differ from in-sample (or training) predictions? This is an important idea from the last lesson.\n",
    "\n",
    "### Step 4: Calculate the Mean Absolute Error in Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb08881b-633e-4922-87a8-5664e8360a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29652.931506849316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "val_mae = mean_absolute_error(val_y, val_predictions)\n",
    "\n",
    "print(val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da114b-947f-4ad0-bfe8-608db9952818",
   "metadata": {},
   "source": [
    "Is that **MAE** good? There isn't a general rule for what values are good that applies to across applications. But you'll see how to use (and improve) this number in the next step.\n",
    "# _____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca0e39-9897-46c5-ab94-4dad14aa55fd",
   "metadata": {},
   "source": [
    "# Underfitting and Overfitting \n",
    "\n",
    "Fine-tune the model for better performance\n",
    "\n",
    "At the end of this step, we will understand the concepts of underfitting and overfitting, and we'll be able to apply these ideas to make your models more accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787858e-01bc-4ee1-9621-0a8652b92dc2",
   "metadata": {},
   "source": [
    "## Experimenting With Different Models\n",
    "\n",
    "Now that I have a reliable way to measure model accuracy, we can experiment with alternative models and see which gives the best predictions. But what alternatives do I have for models?\n",
    "\n",
    "We can see in ***scikit-learn***'s [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) that the decision tree model has many options (more than you'll want or need for a long time). The most important options determine the tree's depth. Recall from [the first lesson in this course](https://www.kaggle.com/code/dansbecker/how-models-work/tutorial) that a tree's depth is a measure of how many splits it makes before coming to a prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea94e56-a99e-4585-8fd4-a1ab49dcb93e",
   "metadata": {},
   "source": [
    "<figure> \n",
    "    <img src=\"http://i.imgur.com/R3ywQsR.png\" alt=\"Shallow Tree\"/>\n",
    "    <figure-caption> Shallow Tree</figure-caption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b616c68-3142-4980-819e-9ad32b196c5d",
   "metadata": {},
   "source": [
    "In practice, it's not uncommon for a tree to have 10 splits between the top level (all houses) and a leaf. As the tree gets deeper, the dataset gets sliced up into leaves with fewer houses. If a tree only had 1 split, it divides the data into 2 groups. If each group is split again, we would get 4 groups of houses. Splitting each of those again would create 8 groups. If we keep doubling the numbers of groups by adding more splits at each level, we'll have 2<sup>10</sup> groups of houses by the time we get to the 10<sup>th</sup> level. That's 1024 leaves.\n",
    "\n",
    "When we divide the houses amongst many leaves, we also have fewer houses in each leaf. Leaves with very few houses will make predictions that are quite close to those homes actual values, but they may make very unreliable predictions for new data (because each prediction is based on only a few houses).\n",
    "\n",
    "This is a phenomenon called **overfitting**, where a model matches the training data almost perfectly, but does poorly in validation and other new data. On the flip side, if we make our tree very shallow, it doesn't divide up the houses into very distinct groups. \n",
    "\n",
    "At an extreme, if a tree divides houses into only 2 or 4, each group still has a wide variety of houses. Resulting predictions may be far off for most houses, even in the training data( and it will be bad in validation too for the same reason). When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called **underfitting**.\n",
    "\n",
    "Since we care about accuracy on new data, which we estimate from our validation data, we want to find the sweet spot between underfitting and overfitting. Visually, we want the low point of the (red) validation curve in the figure below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78536674-f346-4c23-8091-0c6db871f8a6",
   "metadata": {},
   "source": [
    "## Mean Absolute Error\n",
    "<figure>\n",
    "<img src=\"http://i.imgur.com/AXSEOfI.png\" alt=\"MAE example\"/>\n",
    "\n",
    "</figure>\n",
    "\n",
    "\n",
    "## Example \n",
    "\n",
    "There are a few alternatives for controlling the tree depth, and many allow for some reoutes through the tree to have greater depth than other routes. But the *max_leaf_nodes* argument provides a very sensible way to control overfitting vs underfitting. The more leaves we allow the model to make, the more we move from the underfitting area in the above graph to the overfitting area. \n",
    "\n",
    "We can use a utility function to help compare **MAE** scores from different values for *max_leaf_nodes*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f59cecc-a3d3-4b06-8a23-0a30b54bbb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return (mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43b1f3-9813-4f60-96b9-74f07b1ad719",
   "metadata": {},
   "source": [
    "The data is loaded into **train_X, val_X, train_y** and **val_y** using the code you've already seen (and which you've already written).\n",
    "\n",
    "We can use a for-loop to compare the accuracy of models built with different values for *max_leaf_nodes*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "674024e8-daaf-41a1-8efb-8ad2ece240ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5 \t\t Mean Absolute Error: 35044\n",
      "Max leaf nodes: 50 \t\t Mean Absolute Error: 27405\n",
      "Max leaf nodes: 500 \t\t Mean Absolute Error: 29454\n",
      "Max leaf nodes: 5000 \t\t Mean Absolute Error: 30139\n"
     ]
    }
   ],
   "source": [
    "# compare MAE with differing values of max_leaves_nodes\n",
    "\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d \\t\\t Mean Absolute Error: %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258412d6-3c89-43dd-a484-77eb1526e456",
   "metadata": {},
   "source": [
    "Of the options listed, 50 is the optimal number of leaves. It gives the least amount of error. \n",
    "\n",
    "________\n",
    "\n",
    "## Conclusion \n",
    "\n",
    "Here's the takeaway: Models can suffer from either:\n",
    "\n",
    "- **Overfitting**: capturing spurious patterns that won't recur in the future, leading to less accurate predictions, or \n",
    "\n",
    "- **Underfitting**: failing to capture relevant patterns, aggain leading to less accurate predictions.\n",
    "\n",
    "We use **validation** data, which isn't used in model training, to measure a candidate model's accuracy. This lets us try many candidate models and keep the best one. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aec312-646c-4dad-9efd-2c27af405993",
   "metadata": {},
   "source": [
    "# _________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db7607b-5301-4463-9b7b-c6fd0944d28a",
   "metadata": {},
   "source": [
    "### Compare Different Tree Sizes\n",
    "\n",
    "Writing a loop that tries the following values for *max_leaf_nodes* from a set of possible values. \n",
    "\n",
    "Call the *get_mae* function on each value of *max_leaf_nodes*. Store the output  in some way that allows you to select the value of *max_leaf_nodes* that gives the most accurate model on your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0184c187-5594-4afb-9b0b-099ea17d51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this case the following loop is another way to produce the same results as above.\n",
    "\n",
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "\n",
    "# Write a loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "# Here is a short solution with a dict comprehension\n",
    "\n",
    "scores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}\n",
    "\n",
    "# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "\n",
    "best_tree_size = min(scores, key=scores.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439640e6-e768-43d6-b631-f6fd09b0f3c2",
   "metadata": {},
   "source": [
    "### Fit Model Using All Data\n",
    "\n",
    "You know the nest tree size. If you were going to deploy this model in practice, you would make it even more accurate by using all of the data and keeping that tree size. That is, you don't need to hold out the validation data now that you've made all your modeling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2623cc2d-daa4-421d-aea2-fd1b92e32082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16815.938748057826\n"
     ]
    }
   ],
   "source": [
    "final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "final_model.fit(X, y)\n",
    "\n",
    "predict_final = final_model.predict(val_X)\n",
    "maer = mean_absolute_error(val_y, predict_final)\n",
    "\n",
    "print(maer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eef181-0eb0-4d46-9e63-a370d6b7418c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (v3.10.7:6cc6b13308, Sep  5 2022, 14:02:52) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
